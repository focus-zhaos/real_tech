# 音乐的数字记录 — 音调和音色到底是怎么存储的

(对应的博客链接：http://blog.jcix.top/2019-12-17/music-representation/)

经过我在网上的调研，想研究音乐的数字表示/处理，[1-5]中都是很好的参考资料，我并非专业，也并没读完这些资料，只是希望帮助同样好奇题目所示问题的人更快的得到一个直观易懂的答案。

本文首先介绍音乐及其表示的一些方法，然后介绍其数字表示，并解释数字的数值/统计特性与人耳对声音的感受(如音色、音调、响度等)是怎样一一对应的。

### 声音

声音的物理成因是物体的震动，物体的震动引起空气的震动最后被人耳的鼓膜感受到，震动频率的高低也就决定了音调的高低。比如一个音叉之所以会产生声音被我们听到，是因为它在做简谐震动；音响或耳机之所以可以发声，是因为喇叭上振膜的被电磁驱动而震动。

### 音乐的记录

抛开数字音乐不谈，我们平时熟知的音乐都是可以通过乐谱，比如大家小时候学的简谱，五线谱，或者吉他用的6线谱等。

提到这些**乐谱**，首先想到的是一些大家所熟悉的概念：比如，**Pitch** (音高)可以表示音调的高低。**octave** (八度)， 指的是高音是低音频率的两倍。**Pitch class**表示某个八度之中音的集合，比如C调、D调等 [6]…… 每一种不同的乐谱都有对这些基本的音乐特征的记录形式，主要表现为时间和音调的各种关系。

**数字音频格式** (无论是MIDI，WAV还是MP3) 也可以理解成为一种乐谱，一般的数字音频格式也的确是按照时间流逝的顺序记录声音的，只不过那是一种适合机器阅读(解析)的数字格式。在我看来，无论乐谱/格式更适合人看还是计算机看，声音的记录无异于都是信息的记录，没有什么本质的区别。

### 音调

震动都存在震动频率，这个震动的频率也就对应了人感觉上的**音调**。比如人们规定440Hz的震动为A4调，那么880Hz的音调就比A调高了8度(同时440Hz的整数倍也称440Hz的泛音)。比如下图为一个约440Hz的铃声的波形[1]，其很类似于纯粹的表示简谐运动的正弦波形：

[[others_013_p1.png]]

音调在乐谱或者和乐谱类似的记录音符的数字格式(如MIDI)中占据着重要位置，是记录音乐的基本单元；但是在通用音频格式(如WAV)中，却是由其波形记录形式所能导致的必然。也就是说，乐谱和MIDI格式重在标识每个小时间单元的音调(频率)，而WAV等通用音频格式则直接记录被数字采样量化的音频波形。

### 响度

对于WAV等记录波形的格式，响度其实是波形中最直观的量，波形的幅度便是**响度**的直接表示。比如图1中的最大幅度可能被归一化了，这时小于1的幅度便表示了那个时间点声音"不那么响"的信息。而非波形记录的乐谱、MIDI格式等则一定有额外的信息表示某个时间片所演奏/播放声音的**响度**。

讲完音调和响度，或许我们可以更简单的理解成：乐谱/MIDI格式是基于音调和时间的记录，而波形格式是基于响度和时间的记录。

###  音色

通过刚才的解释，我们知道频率不同音高又不同。频率和周期包含相同的信息，当我们说一个波形有一定的频率`f`，那么我们默认其周期`T = 1/f`，并且每个周期`T`内波形是在时间方向上循环出现的。如果学过傅里叶变换，我们就可以理解最简单基本的波形是正弦波形。声音的音色各异的原因就在于`T`中波形是变化的，比如，小提琴的波形和铃声的波形就不同。比如下图是小提琴的波形[2]：

[[others_013_p2.png]]

我们很容易觉察它比图1铃声的波形是复杂度多的，但也具有相同点：虽然小提琴的明显更为复杂，但它们的波形都是重复周期，而且感觉上，图2波形的整体走势和图1的频率类似的，都是2ms左右。这种主导波形的相似其实就说明了两个声音音调的相似，它们可能都是在演奏A4调！

他们表现出的整体音调(基础频率)可能相似，但图2中波形的复杂性在数学上是可以被分解成更多的基本的、类似图1的正弦波。换句话说，虽然它们的音高很类似，但是声音给人的感受(即**音色**)却一定不同。一般情况下，人们会对更复杂的波形周期给出音色丰富、温和或者有趣的评价[2]。

### 连续信息的01存储

信息记录在计算机领域/信息领域是一个共通的问题，更少的数据量肯定对应更大的信息损失。这是因为我们永远无法记录连续信息，比如图1、2中的波形在时间和幅度上都应该是连续的，但是大家都知道信息在计算机中是通过0和1离散存储的，这是因为不可能将1秒的时间无限细分。所以，有损的记录并非数字音频记录的局限，而是信息记录的必然局限，纸质乐谱的信息记录量甚至更差：它只能在持续数秒的一个小节中记录几个音符。

对应于数字波形，有损的记录指的是：我们在时间轴上在每秒只会记录44100 (44.1KHz) 个样本，而非将时间无限切片；在幅度轴上，一般也会选择将响度量化为16bit，即每个时间点有2^16种响度的可能。这里，44.1kHz 和 16 bit这两个值当然是人为规定的可调参数，但也有一定依据(比如44.1kHz是基于那奎斯特采样定律和人耳对20~20kHz声音最敏感这一基本事实)，这种合理的设定也保证了有限的01存储可以存储大部分情况下满足人类所需的各种音频。

### 总结

简单来说，响度、音调、音色并非互不相关的三种声音属性。波形记录可以通过在时间维度上记录响度，间接地记录音调和音色；乐谱可以通过在纸上用时间维度上记录音调、演奏强度和演奏乐器来记录音乐。数字音频格式的设计也并非一个计算机问题，而是一个与乐谱类似通用的信息记录问题。

本文并未讨论数字音频的压缩、编解码和播放等技术，也并未涉及乐理、人对音乐的感受和波形频率的关系，待我以后研究明白点了再和大家聊一聊。本文欢迎留言交流，若有错误，也麻烦指出~

---

[1] Think DSP, https://greenteapress.com/wp/think-dsp/

[2] Notes on Music Information Retrieval, https://musicinformationretrieval.com/

[3] Müller, Meinard. Fundamentals of music processing: Audio, analysis, algorithms, applications. Springer, 2015.

[4] https://www.zhihu.com/question/25914668

[5] https://blog.csdn.net/qqqeeebbb/article/details/100582684

[6] https://musicinformationretrieval.com/sheet_music_representations.html